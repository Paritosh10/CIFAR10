{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "batch2_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "batch3_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "batch4_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "batch5_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "test_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")\n",
    "meta_dict = unpickle(\"CIFAR10/cifar-10-batches-py/data_batch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking keys of all the dataset dictionaries\n",
    "\n",
    "#batch1_dict.keys()\n",
    "test_dict.keys()\n",
    "#meta_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch_1 = batch1_dict[b'data']\n",
    "xbatch_2 = batch2_dict[b'data']\n",
    "xbatch_3 = batch3_dict[b'data']\n",
    "xbatch_4 = batch4_dict[b'data']\n",
    "xbatch_5 = batch5_dict[b'data']\n",
    "xtest = test_dict[b'data']\n",
    "ybatch_1 = batch1_dict[b'labels']\n",
    "ybatch_2 = batch2_dict[b'labels']\n",
    "ybatch_3 = batch3_dict[b'labels']\n",
    "ybatch_4 = batch4_dict[b'labels']\n",
    "ybatch_5 = batch5_dict[b'labels']\n",
    "ytest = test_dict[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch1 = np.array(xbatch_1)\n",
    "xbatch2 = np.array(xbatch_2)\n",
    "xbatch3 = np.array(xbatch_3)\n",
    "xbatch4 = np.array(xbatch_4)\n",
    "xbatch5 = np.array(xbatch_5)\n",
    "x_test = np.array(xtest)\n",
    "ybatch1 = np.array(ybatch_1)\n",
    "ybatch2 = np.array(ybatch_2)\n",
    "ybatch3 = np.array(ybatch_3)\n",
    "ybatch4 = np.array(ybatch_4)\n",
    "ybatch5 = np.array(ybatch_5)\n",
    "y_test = np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((xbatch1, xbatch2, xbatch3, xbatch4))\n",
    "y_train = np.concatenate((ybatch1, ybatch2, ybatch3, ybatch4))\n",
    "x_valid = xbatch5\n",
    "y_valid = ybatch5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reshape(dataset):\n",
    "  new_reshaped = []\n",
    "  for i in range (np.shape(dataset)[0]):\n",
    "    r = dataset[i][:1024]\n",
    "    g = dataset[i][1024:2048]\n",
    "    b = dataset[i][2048:3072]\n",
    "    r = np.reshape(r,(32, 32))\n",
    "    g = np.reshape(g,(32, 32))\n",
    "    b = np.reshape(b,(32, 32))\n",
    "    rgb = np.dstack((r,g,b))\n",
    "    new_reshaped.append(rgb)\n",
    "    \n",
    "  new_reshaped = np.array(new_reshaped)\n",
    "  return new_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = image_reshape(x_train)\n",
    "x_test = image_reshape(x_test)\n",
    "x_valid = image_reshape(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.transpose((0, 3, 1, 2))\n",
    "x_test = x_test.transpose((0, 3, 1, 2))\n",
    "x_valid = x_valid.transpose((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainTensor = torch.from_numpy(x_train)\n",
    "xtestTensor = torch.from_numpy(x_test)\n",
    "xvalidTensor = torch.from_numpy(x_valid)\n",
    "\n",
    "ytrainTensor = torch.from_numpy(y_train).long()\n",
    "ytestTensor = torch.from_numpy(y_test).long()\n",
    "yvalidTensor = torch.from_numpy(y_valid).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = utils.TensorDataset(xtrainTensor, ytrainTensor) \n",
    "test_dataset = utils.TensorDataset(xtestTensor, ytestTensor)\n",
    "valid_dataset = utils.TensorDataset(xvalidTensor, yvalidTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 2048\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 7, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(7, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "moment = 0.4\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = moment, nesterov = False)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paritosh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n",
      "C:\\Users\\Paritosh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/6, Iter : 100/312,  Loss: 2.3058\n",
      "Epoch : 1/6, Iter : 200/312,  Loss: 2.3024\n",
      "Epoch : 1/6, Iter : 300/312,  Loss: 2.3043\n",
      "Epoch : 2/6, Iter : 100/312,  Loss: 2.3051\n",
      "Epoch : 2/6, Iter : 200/312,  Loss: 2.3020\n",
      "Epoch : 2/6, Iter : 300/312,  Loss: 2.3004\n",
      "Epoch : 3/6, Iter : 100/312,  Loss: 2.3046\n",
      "Epoch : 3/6, Iter : 200/312,  Loss: 2.3008\n",
      "Epoch : 3/6, Iter : 300/312,  Loss: 2.2920\n",
      "Epoch : 4/6, Iter : 100/312,  Loss: 2.3009\n",
      "Epoch : 4/6, Iter : 200/312,  Loss: 2.2998\n",
      "Epoch : 4/6, Iter : 300/312,  Loss: 2.2905\n",
      "Epoch : 5/6, Iter : 100/312,  Loss: 2.2967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d794d29790dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
